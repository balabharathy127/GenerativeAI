{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPsDTtZBw1M5lOXTdTU5DT2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"13u7Ymcmjph_hrd1ARe1qgdVTEDkiWJtl"},"id":"SPVP2XpPFFDG","outputId":"26f5c48c-ca43-43d0-e670-c0c6a1238f6f"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Load the Fashion MNIST dataset\n","(x_train, _), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n","x_train = x_train / 255.0  # Normalize pixel values to be between 0 and 1\n","x_train = np.expand_dims(x_train, axis=-1)  # Add channel dimension\n","\n","# Define the generator and discriminator models\n","def build_generator(latent_dim):\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(128, input_dim=latent_dim, activation='relu'))\n","    model.add(layers.Dense(784, activation='sigmoid'))\n","    model.add(layers.Reshape((28, 28, 1)))\n","    return model\n","\n","def build_discriminator(img_shape):\n","    model = tf.keras.Sequential()\n","    model.add(layers.Flatten(input_shape=img_shape))\n","    model.add(layers.Dense(128, activation='relu'))\n","    model.add(layers.Dense(1, activation='sigmoid'))\n","    return model\n","\n","# Define the GAN model\n","def build_gan(generator, discriminator):\n","    discriminator.trainable = False\n","    model = tf.keras.Sequential()\n","    model.add(generator)\n","    model.add(discriminator)\n","    return model\n","\n","# Build and compile the discriminator\n","img_shape = (28, 28, 1)\n","discriminator = build_discriminator(img_shape)\n","discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Build and compile the generator\n","latent_dim = 100\n","generator = build_generator(latent_dim)\n","\n","# Build and compile the GAN model\n","discriminator.trainable = False\n","gan = build_gan(generator, discriminator)\n","gan.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# Training parameters\n","epochs = 10000\n","batch_size = 64\n","\n","for epoch in range(epochs):\n","    # Generate random noise as input to the generator\n","    noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n","\n","    # Generate fake images using the generator\n","    generated_images = generator.predict(noise)\n","\n","    # Select a random batch of real images from the dataset\n","    idx = np.random.randint(0, x_train.shape[0], batch_size)\n","    real_images = x_train[idx]\n","\n","    # Create labels for the generated and real images\n","    labels_real = np.ones((batch_size, 1))\n","    labels_fake = np.zeros((batch_size, 1))\n","\n","    # Train the discriminator on real and fake images separately\n","    d_loss_real = discriminator.train_on_batch(real_images, labels_real)\n","    d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)\n","\n","    # Calculate the total discriminator loss\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","    # Train the generator by fooling the discriminator\n","    noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n","    labels_gan = np.ones((batch_size, 1))\n","    g_loss = gan.train_on_batch(noise, labels_gan)\n","\n","    # Print progress and save generated images at certain intervals\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}\")\n","        # Save generated images\n","        gen_imgs = generator.predict(np.random.normal(0, 1, size=(16, latent_dim)))\n","        gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale generated images to [0, 1]\n","        fig, axs = plt.subplots(4, 4)\n","        count = 0\n","        for i in range(4):\n","            for j in range(4):\n","                axs[i, j].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n","                axs[i, j].axis('off')\n","                count += 1\n","        plt.show()"]}]}